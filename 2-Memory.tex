\subsection{Memory Management and File Access}
\label{sec:fileIO}
One of the primary goals of the \code{gadfly} project is to enable the analysis of large datasets on machines with limited memory.
Enabling this requires intelligent memory management, loading only the particle data of interest from the disk.
Fortunately the HDF5 protocol is well-suited to such non-contiguous file access, allowing not only individual data fields to be accessed independently, but also for the loading of select entries only from the field in question.

\code{Gadfly} allows two complementary approaches to minimizing the memory footprint.
The first method requires definition of a refinement criterion, such as particles above a given density threshold.
The resulting `refined' index can then be used to select only the corresponding values from subsequently loaded particle fields.
While this method is efficient, it is poorly suited to exploratory analysis where the proper refinement criterion may not be know {\it{a priori}}.
However, when additional fields are loaded into an existing \code{PartType} dataframe that has been manually refined, particles not in the existing data are dropped.
This allows for the incremental refinement along several axes of the data kept in memory.
Additional cuts can be made as subsequent fields are loaded, resulting in the selection of a precisely targeted primary dataset from which derived properties (e.g., temperature) may be calculated, serving to reduce computational overhead as well.